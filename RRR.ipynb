{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This code is a modification of https://github.com/chry-santhemum/R3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EfRgH0JfPiQF"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import os\n",
        "import csv\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.distributions.categorical import Categorical\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from tqdm.notebook import tqdm\n",
        "import gym\n",
        "from minigrid.wrappers import ObservationWrapper\n",
        "from typing_extensions import Self\n",
        "from copy import deepcopy\n",
        "from blackjack_numerical_actions import BlackjackEnv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ClapdlOtPiQH"
      },
      "outputs": [],
      "source": [
        "def get_device() -> torch.device:\n",
        "    \"\"\"\n",
        "    Returns the device to use for training.\n",
        "    \"\"\"\n",
        "    #return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    return torch.device(\"cpu\")\n",
        "\n",
        "def set_random_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "# Function from https://github.com/ikostrikov/pytorch-a2c-ppo-acktr/blob/master/model.py\n",
        "def init_params(m):\n",
        "    \"\"\"\n",
        "    Initialize parameters of the network.\n",
        "    m: torch.nn.Module\n",
        "    \"\"\"\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find(\"Linear\") != -1:\n",
        "        m.weight.data.normal_(0, 1)\n",
        "        m.weight.data *= 1 / torch.sqrt(m.weight.data.pow(2).sum(1, keepdim=True))\n",
        "        if m.bias is not None:\n",
        "            m.bias.data.fill_(0)\n",
        "\n",
        "class ImgObsWrapper(ObservationWrapper):\n",
        "    \"\"\"\n",
        "    Use the image as the only observation output, no language/mission.\n",
        "\n",
        "    Parameters:\n",
        "    - env (gym.Env): The environment to wrap.\n",
        "\n",
        "    Methods:\n",
        "    - observation(self, obs): Returns the image from the observation.\n",
        "    - reset(self): Resets the environment and returns the initial observation.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, env):\n",
        "        \"\"\"\n",
        "        Initializes the ImgObsWrapper with the given environment.\n",
        "\n",
        "        Parameters:\n",
        "        - env (gym.Env): The environment whose observations are to be wrapped.\n",
        "        \"\"\"\n",
        "        super().__init__(env)\n",
        "        self.observation_space = env.observation_space.spaces[\"image\"]\n",
        "\n",
        "    def observation(self, obs):\n",
        "        \"\"\"\n",
        "        Extracts and returns the image data from the observation.\n",
        "\n",
        "        Parameters:\n",
        "        - obs (dict or tuple): The original observation from the environment, which could be either\n",
        "        a dictionary or a tuple containing a dictionary.\n",
        "\n",
        "        Returns:\n",
        "        - np.ndarray: The image data extracted from the observation.\n",
        "        \"\"\"\n",
        "        if type(obs) == tuple:\n",
        "            return obs[0][\"image\"]\n",
        "        return obs[\"image\"]\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "        Resets the environment and returns the initial observation image.\n",
        "\n",
        "        Returns:\n",
        "        - np.ndarray: The initial observation image of the reset environment.\n",
        "        \"\"\"\n",
        "        obs = super().reset()\n",
        "        return obs[0]\n",
        "\n",
        "class Config:\n",
        "    \"\"\"\n",
        "    Stores algorithmic hyperparameters.\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                score_threshold=0.93,\n",
        "                discount=1,\n",
        "                lr=1e-3,\n",
        "                max_grad_norm=0.5,\n",
        "                log_interval=10,\n",
        "                gae_lambda=0.95,\n",
        "                clip_ratio=0.2,\n",
        "                target_kl=0.01,\n",
        "                train_ac_iters=5,\n",
        "                use_discounted_reward=True,\n",
        "                use_gae=True,\n",
        "                importance_sampling_clip=2.0,\n",
        "                bad_fit_threshold=0.8,\n",
        "                bad_fit_increment=None,\n",
        "                replay_buffer_capacity=10,\n",
        "                large_buffer_capacity=20):\n",
        "\n",
        "        self.score_threshold = score_threshold # criterion for early stopping. If the rolling average reward (over the last 100 episodes) is greater than it, it ends.\n",
        "        self.discount = discount # discount factor\n",
        "        self.lr = lr # learning rate\n",
        "        self.max_grad_norm = max_grad_norm # the maximum gradient norm (https://pytorch.org/docs/stable/generated/torch.nn.utils.clip_grad_norm_.html)\n",
        "        self.log_interval = log_interval # logging interval\n",
        "        self.clip_ratio = clip_ratio # clip_ratio of PPO.\n",
        "        self.target_kl = target_kl # target KL divergence for early stoping train_ac_iters for PPO\n",
        "        self.train_ac_iters = train_ac_iters # how many time to train ac_model using current computed old_logps\n",
        "        self.gae_lambda=gae_lambda # lambda in Generalized Advantage Estimation (GAE)\n",
        "        self.use_discounted_reward=use_discounted_reward # whether use discounted reward or not.\n",
        "        self.use_gae = use_gae # whether to use GAE or not.\n",
        "        self.importance_sampling_clip = importance_sampling_clip # importance sampling clip threshold\n",
        "        self.bad_fit_threshold = bad_fit_threshold # threshold for bad fit.\n",
        "        if bad_fit_increment is None:\n",
        "            bad_fit_increment = (1.0 - bad_fit_threshold) / replay_buffer_capacity\n",
        "        self.bad_fit_increment = bad_fit_increment # increment for bad fit.\n",
        "        self.replay_buffer_capacity = replay_buffer_capacity # capacity of replay buffer.\n",
        "        self.large_buffer_capacity = large_buffer_capacity # capacity of large replay buffer.\n",
        "\n",
        "class Machine:\n",
        "    def __init__(self, entropy_coef, init_model:nn.Module, args:Config=None):\n",
        "        \"\"\"\n",
        "        A Machine object consists of a Model and its entropy_coef\n",
        "\n",
        "        Args:\n",
        "            entropy_coef: Entropy coefficient.\n",
        "            init_model: Initial model.\n",
        "            args\n",
        "        \"\"\"\n",
        "        if args is None:\n",
        "            self.args = Config()\n",
        "        else:\n",
        "            self.args = args\n",
        "\n",
        "        self.model = init_model\n",
        "        self.optim = torch.optim.Adam(self.model.parameters(), lr=self.args.lr)\n",
        "        self.coef = entropy_coef\n",
        "        self.device = get_device()\n",
        "\n",
        "    def copy_model(self, other_model:nn.Module) -> None:\n",
        "        \"\"\"\n",
        "        Copy state dict from 'model'. Reset rs.\n",
        "        \"\"\"\n",
        "        state_dict = other_model.state_dict()\n",
        "        for key, v in state_dict.items():\n",
        "            if key in self.model.state_dict():\n",
        "                self.model.state_dict()[key].copy_(v)\n",
        "\n",
        "    def copy_machine(self, other:Self) -> None:\n",
        "        \"\"\"\n",
        "        Copy state dict from 'other'. Reset rs.\n",
        "        \"\"\"\n",
        "        self.copy_model(other.model)\n",
        "\n",
        "    def _compute_discounted_return(self, rewards):\n",
        "        \"\"\"\n",
        "            rewards: reward obtained at timestep.  Shape: (T,)\n",
        "            discount: discount factor. float\n",
        "\n",
        "        ----\n",
        "        returns: sum of discounted rewards. Shape: (T,)\n",
        "        \"\"\"\n",
        "        returns = torch.zeros(*rewards.shape, device=self.device)\n",
        "\n",
        "        R = 0\n",
        "        for t in reversed(range((rewards.shape[0]))):\n",
        "            R = rewards[t] + self.args.discount * R\n",
        "            returns[t] = R\n",
        "        return returns\n",
        "\n",
        "    def _compute_advantage_gae(self, values, rewards, T):\n",
        "        \"\"\"\n",
        "        Compute Adavantage wiht GAE. See Section 4.4.2 in the lecture notes.\n",
        "\n",
        "        values: value at each timestep (T,)\n",
        "        rewards: reward obtained at each timestep.  Shape: (T,)\n",
        "        T: the number of frames, float\n",
        "        gae_lambda: hyperparameter, float\n",
        "        discount: discount factor, float\n",
        "\n",
        "        -----\n",
        "\n",
        "        returns:\n",
        "\n",
        "        advantages : tensor.float. Shape [T,]\n",
        "\n",
        "                    gae advantage term for timesteps 0 to T\n",
        "\n",
        "        \"\"\"\n",
        "        advantages = torch.zeros_like(values)\n",
        "        for i in reversed(range(T)):\n",
        "            next_value = values[i+1]\n",
        "            next_advantage = advantages[i+1]\n",
        "\n",
        "            delta = rewards[i] + self.args.discount * next_value  - values[i]\n",
        "            advantages[i] = delta + self.args.discount * self.args.gae_lambda * next_advantage\n",
        "        return advantages[:T]\n",
        "\n",
        "    def collect_experiences(self, env:gym.Env):\n",
        "        \"\"\"\n",
        "        Collects rollouts and computes advantages.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        exps : dict\n",
        "            Contains actions, rewards, advantages etc as attributes.\n",
        "            Each attribute, e.g. `exps['reward']` has a shape\n",
        "            (self.num_frames, ...).\n",
        "        logs : dict\n",
        "            Useful stats about the training process, including the average\n",
        "            reward, policy loss, value loss, etc.\n",
        "        \"\"\"\n",
        "        device = get_device()\n",
        "\n",
        "        MAX_FRAMES_PER_EP = 300\n",
        "        shape = (MAX_FRAMES_PER_EP, )\n",
        "\n",
        "        actions = torch.zeros(*shape, device=device, dtype=torch.int)\n",
        "        values = torch.zeros(*shape, device=device)\n",
        "        rewards = torch.zeros(*shape, device=device)\n",
        "        log_probs = torch.zeros(*shape, device=device)\n",
        "        obss = [None]*MAX_FRAMES_PER_EP\n",
        "\n",
        "        obs = env.reset()\n",
        "\n",
        "        total_return = 0\n",
        "\n",
        "        T = 0\n",
        "\n",
        "        while True:\n",
        "            # Do one agent-environment interaction\n",
        "            with torch.no_grad():\n",
        "                dist, value = self.model(obs)\n",
        "\n",
        "            dist: Categorical\n",
        "            action = dist.sample()[0]\n",
        "\n",
        "            obss[T] = obs\n",
        "\n",
        "            obs, reward, done = env.step(action.item())\n",
        "\n",
        "            # Update experiences values\n",
        "            actions[T] = action\n",
        "            values[T] = value\n",
        "            rewards[T] = reward\n",
        "            log_probs[T] = dist.log_prob(action)\n",
        "\n",
        "            total_return += reward\n",
        "            T += 1\n",
        "\n",
        "            if done or T >= MAX_FRAMES_PER_EP-1:\n",
        "                break\n",
        "\n",
        "        success = (total_return > 0.5)\n",
        "\n",
        "        discounted_reward = self._compute_discounted_return(rewards[:T])\n",
        "        exps = dict(\n",
        "            obs = torch.tensor(np.array(obss[:T]), device=device),\n",
        "            action = actions[:T],\n",
        "            value  = values[:T],\n",
        "            reward = rewards[:T],\n",
        "            log_prob = log_probs[:T],\n",
        "            discounted_reward = discounted_reward,\n",
        "            T = T\n",
        "        )\n",
        "\n",
        "        logs = {\n",
        "            \"return_per_episode\": total_return,\n",
        "            \"num_frames\": T,\n",
        "            'success': success\n",
        "        }\n",
        "\n",
        "        return exps, logs\n",
        "\n",
        "    def _compute_policy_loss_ppo(self, dist:Categorical, factors, indices, old_logp, actions, advantages):\n",
        "        \"\"\"\n",
        "        Computes the policy loss for PPO.\n",
        "\n",
        "        obs: observeration to pass into acmodel. shape: (T,)\n",
        "        init_logp: log probabilities we get from the agent performing the action. shape: (T,)\n",
        "        old_logp: log probabilities from previous timestep. shape: (T,)\n",
        "        actions: action at this timestep. shape: (T,ImWidth,ImHeight,Channels)\n",
        "        advantages: the computed advantages. shape: (T,)\n",
        "\n",
        "        ---\n",
        "        returns\n",
        "\n",
        "        policy_loss : ppo policy loss as shown in line 6 of PPO alg. tensor.float. Shape (,1)\n",
        "        approx_kl: an appoximation of the kl_divergence. tensor.float. Shape (,1)\n",
        "        \"\"\"\n",
        "        policy_loss, approx_kl = 0, 0\n",
        "\n",
        "        coef = self.coef\n",
        "\n",
        "        entropy = dist.entropy()\n",
        "        logps = dist.log_prob(actions)\n",
        "        r_terms = torch.exp(logps - old_logp)\n",
        "        ppo_loss = torch.min(r_terms * advantages, torch.clamp(r_terms, 1 - self.args.clip_ratio, 1 + self.args.clip_ratio) * advantages)\n",
        "\n",
        "        policy_loss_tensor = factors * ppo_loss + coef * entropy\n",
        "\n",
        "        policy_loss = - torch.mean(policy_loss_tensor[indices])\n",
        "\n",
        "        # approx_kl = torch.sum(torch.exp(old_logp) * (old_logp - logps)) / torch.sum(torch.exp(old_logp))\n",
        "        approx_kl = torch.mean((old_logp - logps) ** 2) / 2\n",
        "\n",
        "        return policy_loss, approx_kl\n",
        "\n",
        "    def _compute_value_loss(self, values, returns):\n",
        "        value_loss = torch.mean((values - returns) ** 2)\n",
        "\n",
        "        return value_loss\n",
        "\n",
        "    def update_parameters(self, sb, update_v=True):\n",
        "        MAX_FRAMES_PER_EP = 300\n",
        "        T = sb['T']\n",
        "        with torch.no_grad():\n",
        "            dist, values = self.model(sb['obs'])\n",
        "        values = values.reshape(-1)\n",
        "        dist: Categorical\n",
        "        old_logp = dist.log_prob(sb['action'])\n",
        "        init_logp = sb['log_prob']\n",
        "\n",
        "        # add 0 to end of values until it has length MAX_FRAMES_PER_EP\n",
        "        values_extended = torch.cat([values, torch.zeros((MAX_FRAMES_PER_EP - len(values), ), device=get_device())], dim=0)\n",
        "        full_reward = torch.cat([sb['reward'], torch.zeros((MAX_FRAMES_PER_EP - len(sb['reward']), ), device=get_device())], dim=0)\n",
        "\n",
        "        if self.args.use_gae:\n",
        "            advantage = self._compute_advantage_gae(values_extended, full_reward, T)\n",
        "        else:\n",
        "            advantage = sb['discounted_reward'] - values.reshape(-1)\n",
        "\n",
        "        for i in range(self.args.train_ac_iters):\n",
        "            self.optim.zero_grad()\n",
        "            dist, values = self.model(sb['obs'])\n",
        "            values = values.reshape(-1)\n",
        "            # policy loss\n",
        "            factors = torch.exp(old_logp - init_logp)\n",
        "            indices = factors < self.args.importance_sampling_clip\n",
        "            fit = torch.mean(indices.to(torch.float32))\n",
        "\n",
        "            loss_pi, approx_kl = self._compute_policy_loss_ppo(dist, factors, indices, old_logp, sb['action'], advantage)\n",
        "            if update_v:\n",
        "                loss_v = self._compute_value_loss(values, sb['discounted_reward'])\n",
        "            else:\n",
        "                loss_v = 0.0\n",
        "\n",
        "            if i == 0:\n",
        "                policy_loss = loss_pi\n",
        "                value_loss = loss_v\n",
        "\n",
        "            loss = loss_v + loss_pi\n",
        "            if approx_kl > 1.5 * self.args.target_kl:\n",
        "                break\n",
        "\n",
        "            loss.backward(retain_graph=True)\n",
        "            self.optim.step()\n",
        "\n",
        "        update_policy_loss = policy_loss.item()\n",
        "        update_value_loss = value_loss.item()\n",
        "\n",
        "        logs = {\n",
        "            \"policy_loss\": update_policy_loss,\n",
        "            \"value_loss\": update_value_loss,\n",
        "            \"fit\": fit.item()\n",
        "        }\n",
        "\n",
        "        return logs\n",
        "\n",
        "    def decrease_prob(self, sb, lr=0.1) -> None:\n",
        "        self.optim.zero_grad()\n",
        "\n",
        "        dist, _ = self.model(sb['obs'])\n",
        "        dist: Categorical\n",
        "        logps = dist.log_prob(sb['action'])\n",
        "\n",
        "        loss = lr * torch.mean(logps)\n",
        "        loss.backward()\n",
        "        self.optim.step()\n",
        "\n",
        "class PPO:\n",
        "    def __init__(self, ACModelClass, env, args:Config=None, seed=0):\n",
        "        \"\"\"\n",
        "        The PPO agent.\n",
        "        \"\"\"\n",
        "\n",
        "        self.env = env\n",
        "\n",
        "        set_random_seed(seed)\n",
        "        model = ACModelClass(use_critic=True).to(get_device())\n",
        "\n",
        "        if args is None:\n",
        "            args = Config()\n",
        "        self.machine = Machine(0.01, model, args)\n",
        "\n",
        "    def train(self, max_episodes:int=10000, nonstop:bool=False, max_frames=float('inf')) -> tuple[list[int], list[float]]:\n",
        "        \"\"\"\n",
        "        Train the PPO agent.\n",
        "\n",
        "        Returns:\n",
        "            num_frames, smooth_rs\n",
        "        \"\"\"\n",
        "\n",
        "        print(f'Start! Agent: PPO.')\n",
        "\n",
        "        is_solved = False\n",
        "\n",
        "        SMOOTH_REWARD_WINDOW = 3000\n",
        "\n",
        "        rewards = [0]*SMOOTH_REWARD_WINDOW\n",
        "\n",
        "        total_smooth_rs = []\n",
        "        total_num_frames = []\n",
        "\n",
        "        num_frames = 0\n",
        "\n",
        "        pbar = tqdm(range(max_episodes))\n",
        "        for update in pbar:\n",
        "\n",
        "            exps, logs1 = self.machine.collect_experiences(self.env)\n",
        "\n",
        "            logs2 = self.machine.update_parameters(exps)\n",
        "\n",
        "            logs = {**logs1, **logs2}\n",
        "\n",
        "            total_num_frames.append(num_frames)\n",
        "            num_frames += logs[\"num_frames\"]\n",
        "\n",
        "            rewards.append(logs[\"return_per_episode\"])\n",
        "\n",
        "            smooth_reward = np.mean(rewards[-SMOOTH_REWARD_WINDOW:])\n",
        "\n",
        "            total_smooth_rs.append(smooth_reward)\n",
        "\n",
        "            data = {'num_frames':num_frames, 'smooth_reward':smooth_reward,\n",
        "                'reward':logs[\"return_per_episode\"], 'policy_loss':logs[\"policy_loss\"], 'value_loss': logs['value_loss'], 'episode':update}\n",
        "\n",
        "            pbar.set_postfix(data)\n",
        "\n",
        "            if not nonstop and smooth_reward >= self.machine.args.score_threshold:\n",
        "                is_solved = True\n",
        "                break\n",
        "            if num_frames >= max_frames:\n",
        "                break\n",
        "\n",
        "        if not nonstop and is_solved:\n",
        "            print('Solved!')\n",
        "\n",
        "        return total_num_frames, total_smooth_rs\n",
        "\n",
        "# create a replay buffer\n",
        "class CyclicBuffer:\n",
        "    def __init__(self, capacity):\n",
        "        self.buffer = []\n",
        "        self.capacity = capacity\n",
        "        self.cur_pos = 0\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.buffer)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        return self.buffer[item]\n",
        "\n",
        "    def append(self, data):\n",
        "        \"\"\"\n",
        "        Adds a new piece of data to the buffer.\n",
        "\n",
        "        Parameters:\n",
        "        - data: The data to be added to the buffer.\n",
        "        \"\"\"\n",
        "        #### TODO (10pts): add data to the buffer\n",
        "        #### if the buffer is not full yet, you can simply append the data to the buffer\n",
        "        #### otherwise, you need to replace the oldest data with the current data (FIFO)\n",
        "        #### Hint: you may find self.cur_pos useful, it can be used as a position index\n",
        "        #### to keep track of where to add data\n",
        "        if len(self.buffer) < self.capacity:\n",
        "            self.buffer.append(data)\n",
        "            self.cur_pos = (self.cur_pos + 1) % self.capacity\n",
        "        else:\n",
        "            self.buffer[self.cur_pos] = data\n",
        "            self.cur_pos = (self.cur_pos + 1) % self.capacity\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        \"\"\"\n",
        "        Randomly selects a batch of data from the buffer. The size of the batch is the minimum of the requested\n",
        "        batch size and the current size of the buffer. If the requested batch size equals the buffer size, all\n",
        "        data in the buffer is returned.\n",
        "\n",
        "        Parameters:\n",
        "        - batch_size (int): The size of the batch to sample.\n",
        "\n",
        "        Returns:\n",
        "        - list: A list containing the sampled batch of data.\n",
        "        \"\"\"\n",
        "        #### TODO (10pts): sample a batch from the buffer\n",
        "        bs = min(batch_size, len(self.buffer))\n",
        "        return random.sample(self.buffer, bs)\n",
        "\n",
        "    def get_all(self):\n",
        "        \"\"\"\n",
        "        Retrieves all data stored in the buffer.\n",
        "\n",
        "        Returns:\n",
        "        - list: A deepcopy of all data currently stored in the buffer.\n",
        "        \"\"\"\n",
        "        return deepcopy(self.buffer)\n",
        "\n",
        "    def clear(self):\n",
        "        \"\"\"\n",
        "        Removes all data from the buffer, effectively resetting its state.\n",
        "        \"\"\"\n",
        "        self.buffer.clear()\n",
        "        self.cur_pos = 0\n",
        "\n",
        "def get_default_config():\n",
        "    config = dict(\n",
        "        learning_rate=0.00025,\n",
        "        gamma=0.99,\n",
        "        memory_size=200000,\n",
        "        initial_epsilon=1.0,\n",
        "        min_epsilon=0.1,\n",
        "        max_epsilon_decay_steps=150000,\n",
        "        warmup_steps=500,\n",
        "        target_update_freq=2000,\n",
        "        batch_size=32,\n",
        "        device=None,\n",
        "        disable_target_net=False,\n",
        "        enable_double_q=True\n",
        "    )\n",
        "    return config\n",
        "\n",
        "class RRR:\n",
        "    def __init__(self, ACModelClass, env, args:Config=None, seed=0):\n",
        "        \"\"\"\n",
        "        The RRR agent.\n",
        "        \"\"\"\n",
        "\n",
        "        self.env = env\n",
        "\n",
        "        set_random_seed(seed)\n",
        "        m1 = ACModelClass(use_critic=True).to(get_device())\n",
        "\n",
        "        if args is None:\n",
        "            args = Config()\n",
        "\n",
        "        self.exploiter = Machine(0.01, m1, args)\n",
        "\n",
        "        m2 = ACModelClass(use_critic=False).to(get_device())\n",
        "        m3 = ACModelClass(use_critic=False).to(get_device())\n",
        "        m4 = ACModelClass(use_critic=False).to(get_device())\n",
        "\n",
        "        self.explorer_random = Machine(0.03, m2, args)\n",
        "        self.explorer_thirsty = Machine(0.02, m3, args)\n",
        "        self.explorer_thirsty.copy_machine(self.exploiter)\n",
        "\n",
        "        self.temp_machine = Machine(0.01, m3, args)\n",
        "        self.explorer_bengbuzhu = Machine(0.5, m4, args)\n",
        "\n",
        "    def _replay(self, machine:Machine, buffer:list, cutoff:float) -> float:\n",
        "        \"\"\"\n",
        "        Replay random sample from buffer on machine.\n",
        "\n",
        "        Args:\n",
        "            machine: Machine to replay on\n",
        "            buffer: list of experiences\n",
        "            cutoff: if fit < cutoff, delete sb from buffer\n",
        "\n",
        "        Returns:\n",
        "            fit\n",
        "        \"\"\"\n",
        "\n",
        "        idx = np.random.randint(len(buffer))\n",
        "        sb = buffer[idx]\n",
        "        logs_replay = machine.update_parameters(sb)\n",
        "        fit = logs_replay['fit']\n",
        "        if fit < cutoff:\n",
        "            # delete sb from buffer\n",
        "            buffer.pop(idx)\n",
        "\n",
        "        return fit\n",
        "\n",
        "    def _add_sb_to_buffer(self, exps, buffer:list, capacity:int) -> None:\n",
        "        buffer.append(exps)\n",
        "        if len(buffer) > capacity:\n",
        "            buffer.pop(0)\n",
        "\n",
        "\n",
        "    def train(self, max_episodes:int=10000, nonstop:bool=False, max_frames=float('inf')) -> tuple[list[int], list[float], list[float]]:\n",
        "        \"\"\"\n",
        "        Train the agent.\n",
        "\n",
        "        Returns:\n",
        "            num_frames, smooth_rs, fits\n",
        "        \"\"\"\n",
        "\n",
        "        print('Start! Agent: RRR.')\n",
        "        RANDOM_MODE = 0\n",
        "        EXPLORE_MODE = 1\n",
        "        EXPLOIT_MODE = 2\n",
        "        mode = RANDOM_MODE\n",
        "\n",
        "        is_solved = False\n",
        "\n",
        "        SMOOTH_REWARD_WINDOW = 3000\n",
        "\n",
        "        rewards = [0]*SMOOTH_REWARD_WINDOW\n",
        "\n",
        "        total_smooth_rs = []\n",
        "        total_num_frames = []\n",
        "        larger_buffer_r = []\n",
        "        buffer_r = []\n",
        "        buffer_no_r = []\n",
        "        fits = []\n",
        "\n",
        "        num_frames = 0\n",
        "\n",
        "        pbar = tqdm(range(max_episodes))\n",
        "        for update in pbar:\n",
        "            total_num_frames.append(num_frames)\n",
        "\n",
        "            if mode == RANDOM_MODE:\n",
        "                exps, logs1 = self.explorer_bengbuzhu.collect_experiences(self.env)\n",
        "                self.explorer_bengbuzhu.update_parameters(exps)\n",
        "                logs2 = self.exploiter.update_parameters(exps)\n",
        "\n",
        "            elif mode == EXPLORE_MODE:\n",
        "                if np.random.rand() < 0.5:\n",
        "                    m = self.explorer_random\n",
        "                else:\n",
        "                    m = self.explorer_thirsty\n",
        "\n",
        "                exps, logs1 = m.collect_experiences(self.env)\n",
        "\n",
        "                m.update_parameters(exps)\n",
        "                logs2 = self.exploiter.update_parameters(exps)\n",
        "\n",
        "                if len(larger_buffer_r) >= 1:\n",
        "                    self._replay(self.explorer_thirsty, larger_buffer_r, cutoff=0.0)\n",
        "\n",
        "            elif mode == EXPLOIT_MODE:\n",
        "                exps, logs1 = self.exploiter.collect_experiences(self.env)\n",
        "\n",
        "                logs2 = self.exploiter.update_parameters(exps)\n",
        "\n",
        "                assert len(buffer_r) > 0, f'buffer_r should not be empty.'\n",
        "\n",
        "                cutoff = self.exploiter.args.bad_fit_threshold + self.exploiter.args.bad_fit_increment * (len(buffer_r) - 1)\n",
        "\n",
        "                if not logs1['success'] and total_smooth_rs[-1] <= 0.5:\n",
        "                    fit = self._replay(self.exploiter, buffer_r, cutoff)\n",
        "                    fits.append(fit)\n",
        "\n",
        "                if len(buffer_r) == 0:\n",
        "                    print(f'At episode {update}, we lost all data in replay buffer...')\n",
        "                    mode = EXPLORE_MODE\n",
        "                    self.explorer_thirsty.copy_machine(self.exploiter)\n",
        "                    self.explorer_random.copy_machine(self.temp_machine)\n",
        "                    self.temp_machine.copy_machine(self.exploiter)\n",
        "\n",
        "            else:\n",
        "                raise ValueError(f'Invalid mode: {mode}')\n",
        "\n",
        "            logs = {**logs1, **logs2}\n",
        "\n",
        "            num_frames += logs[\"num_frames\"]\n",
        "\n",
        "            rewards.append(logs[\"return_per_episode\"])\n",
        "\n",
        "            if logs['success']:\n",
        "                if mode == RANDOM_MODE:\n",
        "                    print(f'First successful data collected at episode {update}! We will be accelerating.')\n",
        "                elif mode == EXPLORE_MODE:\n",
        "                    if m is self.explorer_random:\n",
        "                        info_print = 'random explorer'\n",
        "                    elif m is self.explorer_thirsty:\n",
        "                        info_print = 'thirsty explorer'\n",
        "                    else:\n",
        "                        raise ValueError(f'Invalid explorer: {m}')\n",
        "\n",
        "                    print(f'At episode {update}, {info_print} collected a successful data.')\n",
        "                elif mode == EXPLOIT_MODE:\n",
        "                    pass\n",
        "                else:\n",
        "                    raise ValueError(f'Invalid mode: {mode}')\n",
        "                self._add_sb_to_buffer(exps, buffer_r, self.exploiter.args.replay_buffer_capacity)\n",
        "                self._add_sb_to_buffer(exps, larger_buffer_r, self.exploiter.args.large_buffer_capacity)\n",
        "                mode = EXPLOIT_MODE\n",
        "            else:\n",
        "                self._add_sb_to_buffer(exps, buffer_no_r, self.exploiter.args.replay_buffer_capacity)\n",
        "\n",
        "            smooth_reward = np.mean(rewards[-SMOOTH_REWARD_WINDOW:])\n",
        "\n",
        "            total_smooth_rs.append(smooth_reward)\n",
        "\n",
        "            data = {'num_frames':num_frames, 'smooth_reward':smooth_reward,\n",
        "                'reward':logs[\"return_per_episode\"], 'episode':update}\n",
        "\n",
        "            pbar.set_postfix(data)\n",
        "\n",
        "            if not nonstop and smooth_reward >= self.exploiter.args.score_threshold:\n",
        "                    is_solved = True\n",
        "                    break\n",
        "            if num_frames >= max_frames:\n",
        "                break\n",
        "\n",
        "        if is_solved:\n",
        "            print('Solved!')\n",
        "\n",
        "        return total_num_frames, total_smooth_rs, fits\n",
        "\n",
        "class ACModel(nn.Module):\n",
        "    def __init__(self, use_critic=False, state_dim=3, action_dim=2, hidden_dim=256, dropout_p=0.2):\n",
        "        \"\"\"\n",
        "        Actor-Critic model for flat, vector-based inputs (e.g., Blackjack).\n",
        "\n",
        "        Parameters:\n",
        "        - use_critic (bool): Whether to include a critic network.\n",
        "        - state_dim (int): Dimensionality of the input state (default 3).\n",
        "        - action_dim (int): Number of discrete actions (default 5 for Blackjack).\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.use_critic = use_critic\n",
        "\n",
        "        # Actor network\n",
        "        self.actor = nn.Sequential(\n",
        "            nn.Linear(state_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.Dropout(dropout_p),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.Dropout(dropout_p),\n",
        "            nn.Linear(hidden_dim, action_dim)\n",
        "        )\n",
        "\n",
        "        # Critic network (optional)\n",
        "        if use_critic:\n",
        "            self.critic = nn.Sequential(\n",
        "            nn.Linear(state_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.Dropout(dropout_p),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.Dropout(dropout_p),\n",
        "            nn.Linear(hidden_dim, 1)\n",
        "            )\n",
        "\n",
        "    def forward(self, obs):\n",
        "        \"\"\"\n",
        "        Forward pass through the Actor-Critic model.\n",
        "\n",
        "        Parameters:\n",
        "        - obs (torch.Tensor): Batch of state vectors, shape [batch_size, state_dim].\n",
        "\n",
        "        Returns:\n",
        "        - dist (torch.distributions.Categorical): Action distribution.\n",
        "        - value (torch.Tensor): State value estimate (shape: [batch_size]).\n",
        "        \"\"\"\n",
        "        if not isinstance(obs, torch.Tensor):\n",
        "            obs = torch.tensor(obs, dtype=torch.float32)\n",
        "        if len(obs.shape) == 1:\n",
        "            obs = obs.unsqueeze(0)\n",
        "\n",
        "        logits = self.actor(obs)\n",
        "        dist = Categorical(logits=F.log_softmax(logits, dim=-1))\n",
        "\n",
        "        if self.use_critic:\n",
        "            value = self.critic(obs).squeeze(-1)\n",
        "        else:\n",
        "            value = torch.zeros(obs.shape[0])\n",
        "\n",
        "        return dist, value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276,
          "referenced_widgets": [
            "72befb0a6708495f9886538b2c422359",
            "d624ff6ee43c41edb7e509728280c5a2",
            "e1be1c24293043ea90fe3db664fc8d45",
            "49a638fc581d436e991ef71b10c20c2c",
            "338ccb5be7314c63995627fc2effa47e",
            "1c0d07bb84644076a9be086ab85814b0",
            "637dc6b14c694eabb52d78701a4b54dc",
            "df6fe27865c94e5a85c35a649f830288",
            "295698d83da74722a39dbca606057ba2",
            "dc8f8e7ac15f429caeeaa6ba65f585dc",
            "f92cf38e3b9d4d01973f1cfb333b8a7c",
            "8903e507cb8941b7927c5d0277c83846",
            "25fa5baf326847bf8202b0cb2e8ff425",
            "03cd304b699a4150988dd5524947d3e1",
            "81969587926840bdbe894e7fbff6acb9",
            "281ece4002a345968c42164170cf8d4b",
            "a69c54d7e23941e3a9dde1251ec5afe5",
            "33fe79ff7d8a4864842b8b50404790f6",
            "6e4bc3b0da5442f1b7e22ca6ad500dfd",
            "ac5fe12a3ca8418fac0df48e848f764f",
            "3ec6ffbad6b1447bb7ebff3a7bb781b1",
            "e18cd19bb3cc4ad994656f50305412de",
            "0f620fa797a8477eb9f9cd2fd23d7a4d",
            "7224c759ae42432d995ceb947005ea43",
            "ebc1c3047ec64758a0fb7802bfea98fe",
            "0ffbb09df6614e89a4a62637187f17e8",
            "71441f19bb094ab1b7524703a3e0e60e",
            "56816cfa29ab42e6a921756551d11805",
            "7b3aa6a0a4924909b327e45e6ec1bed8",
            "1b64c40326564a81a157599baf55d108",
            "cfcbc88311eb41bf9f16f4e087f89717",
            "dacc9802276048b695d17ca2b48b5d5c",
            "dd56b13771a1481085299ffe052521d9"
          ]
        },
        "id": "pLTvyzkWPiQM",
        "outputId": "6b658921-6d5a-4bbe-e842-21855df3693d"
      },
      "outputs": [],
      "source": [
        "seed = 42\n",
        "\n",
        "env = BlackjackEnv(\n",
        "        num_decks=6,\n",
        "        dealer_hits_soft_17=False,\n",
        "        allow_double=False,\n",
        "        allow_split=False,\n",
        "        allow_surrender=False\n",
        "    )\n",
        "\n",
        "set_random_seed(seed)\n",
        "\n",
        "config = Config(bad_fit_threshold=0.01, importance_sampling_clip=2.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "max_episodes = 40000\n",
        "\n",
        "agent_RRR = RRR(ACModel, env=env, args=Config(bad_fit_threshold=0.01, importance_sampling_clip=2.0), seed=seed)\n",
        "agent_PPO = PPO(ACModel, env=env, args=config, seed=seed)\n",
        "\n",
        "num_frames_RRR, smooth_rs_RRR, fits_RRR = agent_RRR.train(max_episodes, nonstop=True)\n",
        "num_frames_PPO, smooth_rs_PPO = agent_PPO.train(max_episodes, nonstop=True)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(num_frames_PPO, smooth_rs_PPO, label='PPO')\n",
        "#plt.plot(num_frames_RRR, smooth_rs_RRR, label='R3')\n",
        "plt.xlabel('Time steps')\n",
        "plt.ylabel('Average reward (smoothed)')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_strategy_csv(agent, model_type = 'RRR', filename_prefix=\"RRR_strategy\"):\n",
        "    \"\"\"\n",
        "    Generate a strategy table (hard/soft hands) using the policy from RRR.exploiter.model.\n",
        "\n",
        "    Parameters:\n",
        "    - agent_rrr: an instance of RRR.\n",
        "    - filename_prefix: Prefix for the saved CSV files.\n",
        "    \"\"\"\n",
        "    player_sums = list(range(4, 22))\n",
        "    dealer_cards = list(range(1, 11))\n",
        "    output_dir = \"strategyTable\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Get the actor model from the RRR exploiter's Machine instance\n",
        "    if model_type == 'RRR':\n",
        "        policy_model = agent.exploiter.model\n",
        "    elif model_type == 'PPO':\n",
        "        policy_model = agent.machine.model\n",
        "\n",
        "\n",
        "    for usable in [False, True]:\n",
        "        table = []\n",
        "        header = [\"Player Sum \\\\ Dealer Card\"] + [str(dealer) for dealer in dealer_cards]\n",
        "        table.append(header)\n",
        "\n",
        "        for player_sum in player_sums:\n",
        "            row = [str(player_sum)]\n",
        "            for dealer in dealer_cards:\n",
        "                # Normalize inputs just like in training\n",
        "                state = np.array([player_sum / 21, ((dealer - 2) % 10) / 9, int(usable)], dtype=np.float32)\n",
        "                state_tensor = torch.FloatTensor(state).unsqueeze(0).to(get_device())\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    dist, _ = policy_model(state_tensor)\n",
        "                    action = torch.argmax(dist.probs).item()\n",
        "\n",
        "                row.append(action)\n",
        "            table.append(row)\n",
        "\n",
        "        suffix = \"soft\" if usable else \"hard\"\n",
        "        filename = os.path.join(output_dir, f\"{filename_prefix}_{suffix}.csv\")\n",
        "        with open(filename, mode='w', newline='') as f:\n",
        "            writer = csv.writer(f)\n",
        "            writer.writerows(table)\n",
        "\n",
        "        print(f\"Strategy table ({suffix}) saved to: {filename}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Strategy table (hard) saved to: strategyTable\\RRR_strategy_hard.csv\n",
            "Strategy table (soft) saved to: strategyTable\\RRR_strategy_soft.csv\n"
          ]
        }
      ],
      "source": [
        "generate_strategy_csv(agent_RRR, model_type='RRR', filename_prefix=\"RRR_strategy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Strategy table (hard) saved to: strategyTable\\PPO_strategy_hard.csv\n",
            "Strategy table (soft) saved to: strategyTable\\PPO_strategy_soft.csv\n"
          ]
        }
      ],
      "source": [
        "generate_strategy_csv(agent_PPO, model_type='PPO', filename_prefix=\"PPO_strategy\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "03cd304b699a4150988dd5524947d3e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e4bc3b0da5442f1b7e22ca6ad500dfd",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ac5fe12a3ca8418fac0df48e848f764f",
            "value": 0
          }
        },
        "0f620fa797a8477eb9f9cd2fd23d7a4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7224c759ae42432d995ceb947005ea43",
              "IPY_MODEL_ebc1c3047ec64758a0fb7802bfea98fe",
              "IPY_MODEL_0ffbb09df6614e89a4a62637187f17e8"
            ],
            "layout": "IPY_MODEL_71441f19bb094ab1b7524703a3e0e60e"
          }
        },
        "0ffbb09df6614e89a4a62637187f17e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dacc9802276048b695d17ca2b48b5d5c",
            "placeholder": "​",
            "style": "IPY_MODEL_dd56b13771a1481085299ffe052521d9",
            "value": " 4299/10000 [00:12&lt;00:11, 518.02it/s]"
          }
        },
        "1b64c40326564a81a157599baf55d108": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c0d07bb84644076a9be086ab85814b0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25fa5baf326847bf8202b0cb2e8ff425": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a69c54d7e23941e3a9dde1251ec5afe5",
            "placeholder": "​",
            "style": "IPY_MODEL_33fe79ff7d8a4864842b8b50404790f6",
            "value": "Runs:   0%"
          }
        },
        "281ece4002a345968c42164170cf8d4b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "295698d83da74722a39dbca606057ba2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "338ccb5be7314c63995627fc2effa47e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33fe79ff7d8a4864842b8b50404790f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ec6ffbad6b1447bb7ebff3a7bb781b1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49a638fc581d436e991ef71b10c20c2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc8f8e7ac15f429caeeaa6ba65f585dc",
            "placeholder": "​",
            "style": "IPY_MODEL_f92cf38e3b9d4d01973f1cfb333b8a7c",
            "value": " 0/1 [00:00&lt;?, ?it/s]"
          }
        },
        "56816cfa29ab42e6a921756551d11805": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "637dc6b14c694eabb52d78701a4b54dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e4bc3b0da5442f1b7e22ca6ad500dfd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71441f19bb094ab1b7524703a3e0e60e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7224c759ae42432d995ceb947005ea43": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56816cfa29ab42e6a921756551d11805",
            "placeholder": "​",
            "style": "IPY_MODEL_7b3aa6a0a4924909b327e45e6ec1bed8",
            "value": "Step:  43%"
          }
        },
        "72befb0a6708495f9886538b2c422359": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d624ff6ee43c41edb7e509728280c5a2",
              "IPY_MODEL_e1be1c24293043ea90fe3db664fc8d45",
              "IPY_MODEL_49a638fc581d436e991ef71b10c20c2c"
            ],
            "layout": "IPY_MODEL_338ccb5be7314c63995627fc2effa47e"
          }
        },
        "7b3aa6a0a4924909b327e45e6ec1bed8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81969587926840bdbe894e7fbff6acb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ec6ffbad6b1447bb7ebff3a7bb781b1",
            "placeholder": "​",
            "style": "IPY_MODEL_e18cd19bb3cc4ad994656f50305412de",
            "value": " 0/1 [00:00&lt;?, ?it/s]"
          }
        },
        "8903e507cb8941b7927c5d0277c83846": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_25fa5baf326847bf8202b0cb2e8ff425",
              "IPY_MODEL_03cd304b699a4150988dd5524947d3e1",
              "IPY_MODEL_81969587926840bdbe894e7fbff6acb9"
            ],
            "layout": "IPY_MODEL_281ece4002a345968c42164170cf8d4b"
          }
        },
        "a69c54d7e23941e3a9dde1251ec5afe5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac5fe12a3ca8418fac0df48e848f764f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cfcbc88311eb41bf9f16f4e087f89717": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d624ff6ee43c41edb7e509728280c5a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c0d07bb84644076a9be086ab85814b0",
            "placeholder": "​",
            "style": "IPY_MODEL_637dc6b14c694eabb52d78701a4b54dc",
            "value": "  0%"
          }
        },
        "dacc9802276048b695d17ca2b48b5d5c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc8f8e7ac15f429caeeaa6ba65f585dc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd56b13771a1481085299ffe052521d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df6fe27865c94e5a85c35a649f830288": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e18cd19bb3cc4ad994656f50305412de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1be1c24293043ea90fe3db664fc8d45": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df6fe27865c94e5a85c35a649f830288",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_295698d83da74722a39dbca606057ba2",
            "value": 0
          }
        },
        "ebc1c3047ec64758a0fb7802bfea98fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b64c40326564a81a157599baf55d108",
            "max": 10000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cfcbc88311eb41bf9f16f4e087f89717",
            "value": 4299
          }
        },
        "f92cf38e3b9d4d01973f1cfb333b8a7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
